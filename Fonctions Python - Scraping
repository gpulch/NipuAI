##Fonctions de scraping avec user agent variable et timeout aléatoire lors du requêtage HTTP. La fonction itération permet de scraping plusieurs pages qui se suivent dans le chemin URL.
Les données sont stockées dans une liste contenant un élément par page HTML.

##Fonction de visualisation de graphique matplotli

##Fonction de scraping du site LeCigare.ch des pages produits, renvoie un Datafram Pandas (CSV ou Excel) en retour, il suffit d'itérer sur toutes les pages produits (une centaine). La récupération des champs est dans un 'Try' 'Except' ce qui renvoie une valeur vide si une valeur n'est pas trouvée.


import time
from bs4 import BeautifulSoup
import pandas as pd
import requests
import re
import random
import matplotlib.pyplot as plt
import numpy as np
import streamlit as st


dic_user_agents = {'Mac OS Intel avec Safari' : {'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Encoding': 'gzip, deflate, br', 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.5 Safari/605.1.15',  'Accept-Language': 'fr-ch', 'Connection': 'keep-alive'},
                   'Mac OS M1 avec Opera' : {'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Encoding': 'gzip, deflate, br', 'User-Agent': 'Mozilla/5.0 (Macintosh; Apple Mac M1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36 OPR/79.0.4143.72',  'Accept-Language': 'fr-ch', 'Connection': 'keep-alive'},
                   'Mac OS M1 avec Google Chrome' : {'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Encoding': 'gzip, deflate, br', 'User-Agent': 'Mozilla/5.0 (Macintosh; Apple Mac M1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36',  'Accept-Language': 'fr-ch', 'Connection': 'keep-alive'},
                   'Mac OS Intel avec Google Chrome' : {'Accept' : 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Encoding': 'gzip, deflate, br', 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36',  'Accept-Language': 'fr-ch', 'Connection': 'keep-alive'}}

def requête_HTML(url_page, user_Agents= dic_user_agents):
    
        # Header user agent aléatoire
        user_agent_headers = list(user_Agents.values())[random.randint(0, len(list(user_Agents.values()))-1)]
    
        # Envoyer une requête GET
        response = requests.get(url_page, headers=user_agent_headers)
        
        # Vérifier le code de réponse
        if response.status_code == 200:
            return response.text
        else:
            # Le code de réponse n'est pas 200, il peut y avoir une erreur.
            print("La requête a retourné un code de réponse non valide :", response.status_code, url_page)
        
        
def itération_pages_HTML(url, premièrePage, dernièrePage, requêtageBorneMin = 5, requêtageBorneMax = 10):
       
    #Initialisation des variables
    numéroPage = premièrePage
    liste_HTML = []
    
    while numéroPage <= dernièrePage:
        x = requête_HTML(url + str(numéroPage))
        liste_HTML.append(x)
        return liste_HTML

        # Incrémentation boucle while
        numéroPage += 1
        
        # Requêtage différé
        time.sleep(random.uniform(requêtageBorneMin, requêtageBorneMax))

def graphique(data, x=12, y=8):
    n = len(data)
    plt.figure(figsize=(x, y))
    
    for k, i in zip(data.keys(), range(1, n+1)):
        plt.subplot(n, 1, i)
        plt.plot(data[k])
        plt.title(k)
    
    plt.show()

def scraping_pages_produits_LeCigare(page_HTML):
    
    noms_de_colonnes = ['Nom', 'Terroir', 'Marque', 'Quantité', 'Puissance', 'Arôme principal', 'Prix', 'Disponibilité']
    df = pd.DataFrame(columns=noms_de_colonnes)
    
    soup = BeautifulSoup(page_HTML, 'html.parser')
    
    product_descriptions = soup.find_all('div', class_='product-description')

    for product in product_descriptions:
        
        try:
            name_product = product.find('h2').text.strip()
        except AttributeError:
            name_product = ''
        
        try:
            terr_product = product.find('div', class_='listing_short_description').text.strip()
        except AttributeError:
            terr_product = ''
        
        try:
            puis_product = product.find('p', class_='ndk-feat-group-3').text.strip()
        except AttributeError:
            puis_product = ''
        
        try:
            ar_product = product.find('p', class_='ndk-feat-group-11').text.strip()
        except AttributeError:
            ar_product = ''
        
        try:
            pric_product = product.find('span', class_='price').text.strip()
        except AttributeError:
            pric_product = ''
        
        try:
            disp_product = product.find('span', class_='buy-button').text.strip()
        except AttributeError:
            disp_product = ''
        
        s2 = pd.Series([name_product, terr_product, puis_product, ar_product, pric_product, disp_product], index=['Nom', 'Terroir', 'Puissance', 'Arôme principal', 'Prix', 'Disponibilité'])

        df = pd.concat([df, s2.to_frame().T], ignore_index=True)
    
    df[['Terroir', 'Marque', 'Quantité']] = df['Terroir'].str.split('\n', expand=True)
    return df
